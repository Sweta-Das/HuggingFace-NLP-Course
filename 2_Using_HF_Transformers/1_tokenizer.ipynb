{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace Course for a very long time.\",\n",
    "    \"I love and hate this so much.\"\n",
    "]\n",
    "inputs = tokenizer(\n",
    "    raw_inputs,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2005,  1037,  2200,  2146,  2051,  1012,   102],\n",
      "        [  101,  1045,  2293,  1998,  5223,  2023,  2061,  2172,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.from_pretrained()` : function downloads and caches the configuration as well as the vocabulary associated to a given checkpoint.\n",
    "- `distilbert-base-uncased-finetuned-sst-2-english` : checkpoint used by default for sentiment analysis in the pipeline\n",
    "- `padding=True` : We can see that the 2 sentences that is fed into the tokenizer are not of the same size so, we need to pad the shortest one to be able to build an array. Thus, `padding=True`, leading to trailing 0s in the tensor value of `input_ids`.\n",
    "- `truncation=True` : Ensure that any sentence longer than the maximum that the model can handle gets truncated.\n",
    "- `return_tensors=\"pt\"` : Return PyTorch tensors.\n",
    "\n",
    "`attention_mask` in the inputs indicate where the padding has been applied so that the model doesn't pay attention to it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
